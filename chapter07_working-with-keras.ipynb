{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:55:18.780279: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-14 12:55:18.780557: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-2.78342098e-01,  1.04176223e-01, -6.37443662e-02,\n",
       "         -1.27256915e-01,  1.56536192e-01, -2.29457021e-02,\n",
       "         -1.16277829e-01, -4.00173366e-02, -8.28786790e-02,\n",
       "          1.86833948e-01, -6.11943305e-02,  1.10970438e-01,\n",
       "         -2.06843823e-01,  2.24876761e-01, -2.01764107e-02,\n",
       "          8.09928775e-02,  8.04015696e-02,  2.15747654e-01,\n",
       "         -2.18258768e-01, -2.74422258e-01,  2.13367939e-02,\n",
       "         -2.18868226e-01,  1.64858788e-01,  7.74598122e-03,\n",
       "          5.05762696e-02, -1.66206047e-01, -3.42989266e-02,\n",
       "          4.11494970e-02, -2.04560846e-01,  5.04750907e-02,\n",
       "          7.20031261e-02, -1.93627074e-01, -1.67840838e-01,\n",
       "          5.81833422e-02,  1.02194071e-01,  1.19783282e-01,\n",
       "          2.18534410e-01, -2.21931174e-01,  1.47427320e-02,\n",
       "         -1.76211596e-02, -2.40734071e-01,  2.95623124e-01,\n",
       "          2.82188058e-01, -2.58639216e-01, -1.86300978e-01,\n",
       "          2.90973663e-01,  2.92463958e-01,  2.97528207e-01,\n",
       "         -8.74758661e-02, -2.74719924e-01,  7.27548897e-02,\n",
       "         -5.00135422e-02,  1.41093135e-02, -2.30997205e-02,\n",
       "         -2.23483473e-01, -2.74388373e-01,  1.30885720e-01,\n",
       "         -1.47862762e-01, -4.08937037e-02, -1.39924228e-01,\n",
       "          1.10688031e-01, -1.34502888e-01,  4.88876998e-02,\n",
       "         -1.14815280e-01],\n",
       "        [ 4.72085178e-02,  2.73254931e-01,  1.78630978e-01,\n",
       "         -2.79124767e-01, -1.88146308e-01,  1.42718762e-01,\n",
       "          5.87212145e-02,  2.67857730e-01,  8.54867697e-02,\n",
       "         -1.07592046e-02, -2.42058426e-01,  4.81454730e-02,\n",
       "          4.92826700e-02, -1.47103280e-01,  2.90329754e-01,\n",
       "         -2.01190412e-01,  9.95853245e-02,  1.56900764e-01,\n",
       "          1.33511662e-01,  2.83442616e-01,  6.68967068e-02,\n",
       "          2.12743044e-01,  5.96408844e-02, -3.60589921e-02,\n",
       "         -1.34508520e-01, -2.80331314e-01,  1.71245933e-02,\n",
       "          1.75099015e-01, -1.93663388e-01,  2.63433158e-02,\n",
       "          1.95234954e-01,  2.06633449e-01, -2.09139287e-01,\n",
       "         -2.40400106e-01,  2.62632310e-01, -1.62813768e-01,\n",
       "         -9.12267566e-02, -1.13235652e-01,  2.79262066e-01,\n",
       "          2.26184309e-01,  4.16116714e-02,  2.91827083e-01,\n",
       "          2.43370950e-01, -1.88067555e-02, -1.69266135e-01,\n",
       "          6.17663264e-02, -2.95857608e-01,  1.57351822e-01,\n",
       "          2.63973475e-01, -1.96097195e-01, -6.40246123e-02,\n",
       "          1.22554123e-01, -1.27593100e-01, -2.42926225e-01,\n",
       "          9.87883508e-02,  2.17825174e-04,  1.80528253e-01,\n",
       "          6.73387051e-02,  1.98517442e-01, -5.88222444e-02,\n",
       "         -8.88436735e-02,  1.85122877e-01, -1.15588263e-01,\n",
       "         -8.94723833e-02],\n",
       "        [ 1.70603901e-01,  1.26094252e-01, -1.10973999e-01,\n",
       "          1.55836344e-03, -1.03768632e-01,  2.57526577e-01,\n",
       "          8.17149878e-03,  2.84450233e-01, -8.46938938e-02,\n",
       "         -2.44950145e-01, -2.57997453e-01,  3.07737887e-02,\n",
       "         -1.46898866e-01,  2.18600035e-03,  1.36396378e-01,\n",
       "         -1.01893112e-01, -5.91515154e-02, -4.14430201e-02,\n",
       "         -2.81502217e-01, -7.10544735e-02,  2.71568179e-01,\n",
       "          1.00727946e-01,  1.18007928e-01, -1.24668509e-01,\n",
       "          8.03021789e-02,  1.85623884e-01, -1.02822199e-01,\n",
       "          2.88079202e-01,  2.59427726e-01, -1.76988006e-01,\n",
       "          2.63853252e-01, -1.92525983e-01,  6.71625435e-02,\n",
       "         -2.93406606e-01,  1.05513722e-01, -1.91601515e-01,\n",
       "         -9.97722149e-04, -2.11995751e-01,  1.39756560e-01,\n",
       "          2.79248536e-01, -7.46897012e-02,  1.53593808e-01,\n",
       "          2.32146144e-01,  8.94244313e-02, -1.49442822e-01,\n",
       "         -2.12398797e-01,  1.10902220e-01, -1.09088078e-01,\n",
       "          1.25838816e-01,  2.74704993e-01, -2.97177464e-01,\n",
       "         -9.92743820e-02,  2.73709655e-01,  2.28211164e-01,\n",
       "          1.22890174e-02,  8.74204338e-02,  2.93655038e-01,\n",
       "         -1.12536550e-03, -2.72668898e-01, -5.29596210e-02,\n",
       "         -5.20095229e-03,  2.06103504e-01, -2.71631718e-01,\n",
       "          6.27935231e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-0.10718292,  0.18584967,  0.10532555, -0.2809266 ,  0.16372699,\n",
       "         -0.06227362, -0.11809582,  0.28028783,  0.260888  ,  0.0320245 ],\n",
       "        [-0.19097269, -0.20817477, -0.20940404,  0.01982403,  0.04037818,\n",
       "          0.00552699, -0.00995281, -0.19601706, -0.07385054, -0.0044952 ],\n",
       "        [ 0.03816527, -0.16645843, -0.18096334,  0.28408524, -0.07431573,\n",
       "         -0.06875025,  0.15508008,  0.10371494, -0.05733198,  0.16177714],\n",
       "        [ 0.10182655,  0.1332384 ,  0.02963901, -0.22239617,  0.0847398 ,\n",
       "          0.27852735,  0.18244645,  0.11657763,  0.26075032, -0.27166367],\n",
       "        [ 0.24829218,  0.08617961, -0.10442492, -0.2841121 ,  0.23988208,\n",
       "         -0.06704059,  0.15516475,  0.2364212 ,  0.04277664,  0.16705674],\n",
       "        [-0.04044762, -0.17586589,  0.13966894, -0.04691495,  0.1807298 ,\n",
       "         -0.17018147,  0.08298433, -0.19087052, -0.02937892,  0.0602462 ],\n",
       "        [ 0.18002585, -0.04956581, -0.13480033, -0.17604457,  0.14988312,\n",
       "          0.1902251 , -0.00314516,  0.1062859 , -0.11375146, -0.13252476],\n",
       "        [ 0.1901496 ,  0.07396916, -0.19850817, -0.01683277,  0.11049625,\n",
       "          0.26230422,  0.24951574,  0.01708069, -0.16426419, -0.06032839],\n",
       "        [-0.19102702, -0.0436822 ,  0.09869021, -0.1222088 , -0.04734217,\n",
       "          0.14081177,  0.2268143 ,  0.25726262, -0.22968365,  0.25249037],\n",
       "        [ 0.10961002,  0.27734104,  0.28048137, -0.16856042, -0.13440712,\n",
       "          0.1674475 ,  0.12514439, -0.01226863, -0.16306894,  0.16180938],\n",
       "        [ 0.24606207,  0.03563768, -0.01377964, -0.11080298,  0.02208763,\n",
       "         -0.24843848,  0.07684648,  0.08176404, -0.08986041,  0.19704497],\n",
       "        [-0.16196546, -0.2235344 , -0.20856853,  0.25979164,  0.08443758,\n",
       "          0.03129679, -0.27126518,  0.13715988, -0.08201651, -0.11438636],\n",
       "        [ 0.10823962, -0.16453296, -0.27970323, -0.04298322, -0.23743312,\n",
       "         -0.0526071 ,  0.04362306, -0.00044155, -0.16616318, -0.24284491],\n",
       "        [ 0.21891645, -0.18744668, -0.04391207,  0.2737367 , -0.03611515,\n",
       "         -0.20855597, -0.21742947,  0.20995855, -0.17864214, -0.09197496],\n",
       "        [ 0.12348118, -0.05911896, -0.28268594,  0.23112115,  0.17034298,\n",
       "          0.16706917,  0.24634174,  0.24821731,  0.2300351 , -0.1787841 ],\n",
       "        [-0.00089234,  0.17858797,  0.19154629, -0.25320852, -0.26848307,\n",
       "          0.09428346, -0.10442364, -0.23333493, -0.11156034, -0.28345296],\n",
       "        [ 0.07587078, -0.1966643 ,  0.10006455,  0.2321628 , -0.09245609,\n",
       "         -0.01962817, -0.11175233, -0.03549777,  0.1420005 ,  0.13418418],\n",
       "        [-0.02716038, -0.00546819, -0.17715177,  0.01154664,  0.21281344,\n",
       "         -0.01753065,  0.07934535,  0.08355156,  0.26337287, -0.05120234],\n",
       "        [ 0.20809764,  0.21999457, -0.12645215,  0.21969756, -0.16060653,\n",
       "         -0.11893833, -0.26223037,  0.1786386 ,  0.17881295,  0.01241887],\n",
       "        [-0.21357806,  0.02781883,  0.15693983,  0.06745112, -0.1427369 ,\n",
       "          0.22404972, -0.12288077,  0.11579335, -0.13541806, -0.03233808],\n",
       "        [-0.01909801, -0.25068092, -0.05639023,  0.10986894, -0.21158531,\n",
       "         -0.15507133, -0.09287767,  0.01874423,  0.05207038, -0.16094923],\n",
       "        [ 0.01834199, -0.25542787, -0.26224428, -0.04631773,  0.16481131,\n",
       "         -0.25977916,  0.26741102, -0.00503328, -0.07368129, -0.09376505],\n",
       "        [-0.26902455,  0.2833664 ,  0.01237375, -0.1690991 ,  0.12429491,\n",
       "          0.19512928,  0.25869843,  0.2284368 ,  0.0731191 , -0.23566006],\n",
       "        [ 0.03872156, -0.12093976, -0.1775177 ,  0.09446296,  0.06778175,\n",
       "         -0.25956014, -0.00212637,  0.08399257, -0.08213925, -0.1023161 ],\n",
       "        [-0.09279913,  0.13616973, -0.19071186, -0.04808895,  0.1630933 ,\n",
       "         -0.02335262, -0.04165089,  0.03590328, -0.26131237,  0.14419693],\n",
       "        [-0.18044303, -0.10929997, -0.11114866, -0.2357042 ,  0.14385912,\n",
       "         -0.04319414,  0.16387239, -0.21862051, -0.08397152,  0.00409386],\n",
       "        [-0.19096449,  0.02339995,  0.04360828, -0.18882006,  0.17128149,\n",
       "         -0.08836836, -0.10970785,  0.26770636, -0.03794782,  0.0104197 ],\n",
       "        [ 0.20248798, -0.15967251,  0.148588  , -0.257623  ,  0.00749645,\n",
       "          0.26959655, -0.09486675, -0.26679516, -0.12030798,  0.04975122],\n",
       "        [ 0.14618757,  0.11732581,  0.03353158, -0.05644317,  0.19234806,\n",
       "          0.15098304,  0.0229463 ,  0.01392731,  0.22582796, -0.04249319],\n",
       "        [ 0.10388499, -0.18508807, -0.04765527,  0.18915817, -0.10611625,\n",
       "         -0.19860417, -0.15029031,  0.03674293, -0.03047046, -0.05110364],\n",
       "        [ 0.06169522,  0.0055432 , -0.10795699, -0.23979275,  0.04432619,\n",
       "         -0.19227937,  0.07458672,  0.12841326,  0.19323233,  0.22713593],\n",
       "        [ 0.08531532, -0.23004714, -0.24738416,  0.05871257,  0.01490971,\n",
       "         -0.11809276, -0.07501288,  0.23493657,  0.24555233,  0.17653072],\n",
       "        [ 0.22152081, -0.06715302, -0.01985097, -0.13276862,  0.0421021 ,\n",
       "          0.24521449,  0.2680733 , -0.13383584, -0.00846061,  0.08511525],\n",
       "        [-0.23876476, -0.2646263 ,  0.0930759 ,  0.0524433 ,  0.22690114,\n",
       "         -0.0273115 , -0.2511452 ,  0.02533594, -0.24923265, -0.28200495],\n",
       "        [-0.25348333, -0.10965124, -0.23821452, -0.25109586,  0.05761772,\n",
       "         -0.04202516, -0.11248337,  0.15339264,  0.03593993, -0.28328866],\n",
       "        [ 0.25077346, -0.11031899, -0.05325809,  0.22586283,  0.24619588,\n",
       "         -0.27701008,  0.14026907, -0.09751396,  0.22774407,  0.17598638],\n",
       "        [ 0.14781046, -0.16825423,  0.1754711 ,  0.03675887, -0.16913863,\n",
       "          0.14260119, -0.23593773, -0.00663757, -0.09290048,  0.22548208],\n",
       "        [ 0.10633445,  0.1991559 , -0.22492613, -0.28454128,  0.08775952,\n",
       "          0.09811404,  0.0511665 , -0.00234476,  0.11707661, -0.17344448],\n",
       "        [-0.14377166, -0.10737586, -0.03296584, -0.17848933, -0.00527313,\n",
       "          0.28278032, -0.18537524, -0.17796957, -0.12770836,  0.06674072],\n",
       "        [ 0.27490607, -0.04121417,  0.19721523,  0.02749866,  0.26081797,\n",
       "          0.09159097, -0.16092724,  0.22992077, -0.06107566, -0.19716093],\n",
       "        [ 0.09464809,  0.14061156,  0.21466109,  0.19803703, -0.15541634,\n",
       "         -0.00423208,  0.15277654,  0.17140672,  0.15859741,  0.12809643],\n",
       "        [ 0.22639892,  0.16877514,  0.06903166, -0.27318195,  0.07521334,\n",
       "          0.03433686,  0.0776372 , -0.06497772, -0.0294202 , -0.1389671 ],\n",
       "        [ 0.14097247,  0.02364373,  0.04269814,  0.06919158,  0.19011492,\n",
       "          0.24380949,  0.21669582,  0.237286  , -0.17243077,  0.09334162],\n",
       "        [-0.17812143, -0.09638618, -0.24992688,  0.11353326,  0.11493993,\n",
       "          0.2591705 , -0.17450368,  0.07139981, -0.22957414, -0.17601165],\n",
       "        [ 0.28201208,  0.06100926, -0.18613362,  0.27286252,  0.08421096,\n",
       "          0.21093473, -0.17309825, -0.08876726, -0.18885341,  0.16451985],\n",
       "        [-0.15625314,  0.2582114 ,  0.07282826,  0.07816395,  0.19660613,\n",
       "         -0.03797422, -0.14077389, -0.00569645,  0.27219412, -0.11667097],\n",
       "        [ 0.26041308,  0.0276508 , -0.1289711 ,  0.20057642, -0.01751313,\n",
       "          0.04649106,  0.03575709,  0.1418781 ,  0.08194673,  0.11039191],\n",
       "        [-0.25964174,  0.13279006,  0.0639475 ,  0.2380183 , -0.04455253,\n",
       "          0.09945497, -0.22108638,  0.1765388 , -0.06691262,  0.11705941],\n",
       "        [-0.24502197,  0.20575383,  0.25835332, -0.23758186, -0.24830067,\n",
       "          0.15256852,  0.20231757, -0.12412845,  0.04335627, -0.20331588],\n",
       "        [-0.21868502, -0.0039297 ,  0.08910921, -0.11228661, -0.17925566,\n",
       "          0.04819208, -0.07693394, -0.09732285,  0.26066628, -0.0059016 ],\n",
       "        [ 0.24875799,  0.16016972,  0.14713353,  0.06490535,  0.02718773,\n",
       "          0.1017949 , -0.23290268,  0.05854225, -0.15068291,  0.16876462],\n",
       "        [-0.19027555,  0.15106669,  0.23029974, -0.2323815 , -0.1397753 ,\n",
       "         -0.16126165,  0.04045931,  0.03239095,  0.25892028, -0.2629599 ],\n",
       "        [ 0.09682897,  0.25184038, -0.1083221 , -0.17281346,  0.152165  ,\n",
       "          0.13112164,  0.27892646, -0.09973203, -0.213575  , -0.21834897],\n",
       "        [-0.12367406,  0.02997527,  0.05063975, -0.20652813,  0.09009627,\n",
       "         -0.23232101,  0.01679093,  0.26873943, -0.26479173, -0.255413  ],\n",
       "        [ 0.16617492,  0.25615087,  0.2177504 ,  0.22845516,  0.25833187,\n",
       "          0.19632664, -0.28145143, -0.19846968,  0.14913008, -0.1407762 ],\n",
       "        [ 0.13630068, -0.14125311,  0.23548988, -0.0522369 ,  0.15274504,\n",
       "         -0.25113782,  0.15748778, -0.2032833 , -0.20691977,  0.2359111 ],\n",
       "        [ 0.00755516, -0.23419495,  0.23553964,  0.05152449, -0.08409107,\n",
       "         -0.05318619,  0.10147521,  0.1802243 , -0.2504201 , -0.12738909],\n",
       "        [-0.06155501,  0.02982599, -0.21932182, -0.03626831,  0.03827369,\n",
       "         -0.21065733, -0.16365108, -0.10952468, -0.27878124,  0.14979616],\n",
       "        [-0.19462478,  0.21948221, -0.18294923, -0.18325168,  0.24988982,\n",
       "          0.09482399,  0.27752718,  0.17133477,  0.227132  ,  0.07330015],\n",
       "        [-0.03385505,  0.07938826,  0.13241452,  0.09258813,  0.07652068,\n",
       "         -0.19999856, -0.00514817,  0.00249138,  0.06321579,  0.16763285],\n",
       "        [-0.16758499,  0.025222  , -0.22511655, -0.03482784, -0.17533126,\n",
       "         -0.05170567,  0.07699394,  0.25699338, -0.00428101, -0.23291579],\n",
       "        [-0.2763187 ,  0.107979  , -0.10558312, -0.12506199, -0.14888738,\n",
       "         -0.26790208, -0.00456607,  0.09440362,  0.21990022, -0.17744105],\n",
       "        [-0.2708875 ,  0.07736841, -0.18729162,  0.24587658, -0.10410571,\n",
       "          0.09396362, -0.21640706,  0.22258398, -0.16910604, -0.23728058],\n",
       "        [-0.15274464,  0.04595214, -0.04808101, -0.02680925,  0.2757289 ,\n",
       "         -0.21272483, -0.0709434 , -0.0206427 ,  0.17579576, -0.18617335]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:55:51.514648: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-14 12:55:51.881211: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 12ms/step - loss: 25.2921 - priority_loss: 0.3175 - department_loss: 24.9746 - priority_mean_absolute_error: 0.4811 - department_accuracy: 0.2383\n",
      "13/40 [========>.....................] - ETA: 0s - loss: 31.2499 - priority_loss: 0.3347 - department_loss: 30.9152 - priority_mean_absolute_error: 0.4945 - department_accuracy: 0.2428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:55:53.902952: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 9ms/step - loss: 30.5033 - priority_loss: 0.3234 - department_loss: 30.1799 - priority_mean_absolute_error: 0.4867 - department_accuracy: 0.2430\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:55:54.451435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/40 [=>............................] - ETA: 0s - loss: 47.2075 - priority_loss: 0.3294 - department_loss: 46.8780 - priority_mean_absolute_error: 0.4952 - department_accuracy: 0.2500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:55:58.962437: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 14ms/step - loss: 32.4285 - priority_loss: 0.3234 - department_loss: 32.1051 - priority_mean_absolute_error: 0.4867 - department_accuracy: 0.2609\n",
      "13/40 [========>.....................] - ETA: 0s - loss: 31.4503 - priority_loss: 0.3347 - department_loss: 31.1156 - priority_mean_absolute_error: 0.4945 - department_accuracy: 0.0745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:55:59.749546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 8ms/step - loss: 30.7918 - priority_loss: 0.3234 - department_loss: 30.4684 - priority_mean_absolute_error: 0.4867 - department_accuracy: 0.0672\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:56:00.256085: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x28a169640>,\n",
       " <keras.engine.input_layer.InputLayer at 0x28a1695e0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x28a16b3d0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x28a1547c0>,\n",
       " <keras.layers.core.dense.Dense at 0x28a1545e0>,\n",
       " <keras.layers.core.dense.Dense at 0x28a140df0>,\n",
       " <keras.layers.core.dense.Dense at 0x28a16b970>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/40 [===>..........................] - ETA: 0s - loss: 40.3063 - output_1_loss: 0.2923 - output_2_loss: 40.0140 - output_1_mean_absolute_error: 0.4570 - output_2_accuracy: 0.2448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:56:20.540632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 12ms/step - loss: 26.8674 - output_1_loss: 0.3190 - output_2_loss: 26.5485 - output_1_mean_absolute_error: 0.4829 - output_2_accuracy: 0.2227\n",
      "13/40 [========>.....................] - ETA: 0s - loss: 27.8788 - output_1_loss: 0.3347 - output_2_loss: 27.5441 - output_1_mean_absolute_error: 0.4945 - output_2_accuracy: 0.2428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:56:21.475469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 9ms/step - loss: 27.3738 - output_1_loss: 0.3234 - output_2_loss: 27.0505 - output_1_mean_absolute_error: 0.4867 - output_2_accuracy: 0.2430\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:56:21.934178: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   4/1563 [..............................] - ETA: 26s - loss: 2.2456 - accuracy: 0.2266 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:58:16.192476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2812 - accuracy: 0.9166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:58:26.567466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2812 - accuracy: 0.9166 - val_loss: 0.1605 - val_accuracy: 0.9542\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1536 - accuracy: 0.9563 - val_loss: 0.1360 - val_accuracy: 0.9634\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1251 - accuracy: 0.9665 - val_loss: 0.1181 - val_accuracy: 0.9684\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9695\n",
      " 98/313 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:58:50.456590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:58:51.392833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.9166 - rmse: 7.1973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:59:02.055775: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2842 - accuracy: 0.9167 - rmse: 7.1969 - val_loss: 0.1533 - val_accuracy: 0.9576 - val_rmse: 7.3660\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1534 - accuracy: 0.9571 - rmse: 7.3639 - val_loss: 0.1302 - val_accuracy: 0.9646 - val_rmse: 7.4007\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1242 - accuracy: 0.9665 - rmse: 7.3956 - val_loss: 0.1129 - val_accuracy: 0.9707 - val_rmse: 7.4178\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1120 - accuracy: 0.9715 - rmse: 7.4306\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  17/1563 [..............................] - ETA: 10s - loss: 1.5362 - accuracy: 0.5165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:59:28.784314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2819 - accuracy: 0.9161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:59:38.857074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2818 - accuracy: 0.9162 - val_loss: 0.1600 - val_accuracy: 0.9556\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1523 - accuracy: 0.9574 - val_loss: 0.1231 - val_accuracy: 0.9662\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1234 - accuracy: 0.9666 - val_loss: 0.1130 - val_accuracy: 0.9704\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1131 - accuracy: 0.9702 - val_loss: 0.1074 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1037 - accuracy: 0.9741 - val_loss: 0.1044 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0964 - accuracy: 0.9771 - val_loss: 0.1117 - val_accuracy: 0.9759\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0894 - accuracy: 0.9786 - val_loss: 0.1159 - val_accuracy: 0.9772\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0858 - accuracy: 0.9798 - val_loss: 0.1138 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0834 - accuracy: 0.9812 - val_loss: 0.1235 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0756 - accuracy: 0.9822 - val_loss: 0.1303 - val_accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3e6fcba60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  17/1563 [..............................] - ETA: 10s - loss: 1.4464 - accuracy: 0.5588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:01:16.404838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2827 - accuracy: 0.9154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:01:26.114996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2828 - accuracy: 0.9153 - val_loss: 0.1476 - val_accuracy: 0.9571\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1558 - accuracy: 0.9565 - val_loss: 0.1283 - val_accuracy: 0.9625\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1281 - accuracy: 0.9661 - val_loss: 0.1138 - val_accuracy: 0.9701\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1113 - accuracy: 0.9711 - val_loss: 0.1190 - val_accuracy: 0.9712\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1024 - accuracy: 0.9745 - val_loss: 0.1108 - val_accuracy: 0.9746\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0949 - accuracy: 0.9764 - val_loss: 0.1226 - val_accuracy: 0.9725\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0887 - accuracy: 0.9784 - val_loss: 0.1089 - val_accuracy: 0.9772\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0853 - accuracy: 0.9801 - val_loss: 0.1152 - val_accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0804 - accuracy: 0.9815 - val_loss: 0.1316 - val_accuracy: 0.9761\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0780 - accuracy: 0.9824 - val_loss: 0.1267 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2984dc250>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:03:04.445874: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.9159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:03:14.451455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2859 - accuracy: 0.9159 - val_loss: 0.1446 - val_accuracy: 0.9594\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1533 - accuracy: 0.9567 - val_loss: 0.1264 - val_accuracy: 0.9658\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1260 - accuracy: 0.9663 - val_loss: 0.1135 - val_accuracy: 0.9723\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1144 - accuracy: 0.9693 - val_loss: 0.1143 - val_accuracy: 0.9734\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1051 - accuracy: 0.9734 - val_loss: 0.1146 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0953 - accuracy: 0.9761 - val_loss: 0.1162 - val_accuracy: 0.9751\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0918 - accuracy: 0.9776 - val_loss: 0.1182 - val_accuracy: 0.9768\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0885 - accuracy: 0.9796 - val_loss: 0.1197 - val_accuracy: 0.9748\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0793 - accuracy: 0.9815 - val_loss: 0.1209 - val_accuracy: 0.9763\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0763 - accuracy: 0.9820 - val_loss: 0.1240 - val_accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cfea7730>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/opt/homebrew/bin/tensorboard\", line 5, in <module>\n",
       "    from tensorboard.main import run_main\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/main.py\", line 27, in <module>\n",
       "    from tensorboard import default\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/default.py\", line 33, in <module>\n",
       "    from tensorboard.plugins.audio import audio_plugin\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/plugins/audio/audio_plugin.py\", line 25, in <module>\n",
       "    from tensorboard.data import provider\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/data/__init__.py\", line 17, in <module>\n",
       "    from tensorboard.data import experimental  # noqa: F401\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/data/experimental/__init__.py\", line 17, in <module>\n",
       "    from tensorboard.data.experimental.experiment_from_dev import (  # noqa: F401\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/data/experimental/experiment_from_dev.py\", line 21, in <module>\n",
       "    import grpc\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/grpc/__init__.py\", line 22, in <module>\n",
       "    from grpc import _compression\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/grpc/_compression.py\", line 15, in <module>\n",
       "    from grpc._cython import cygrpc\n",
       "ImportError: dlopen(/opt/homebrew/lib/python3.9/site-packages/grpc/_cython/cygrpc.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/lib/python3.9/site-packages/grpc/_cython/cygrpc.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have (x86_64), need (arm64e)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9190\n",
      "...loss: 0.2750\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9656\n",
      "...loss: 0.1232\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9787\n",
      "...loss: 0.0799\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9603\n",
      "...val_loss: 0.1733\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:05:39.055822: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9603\n",
      "...val_loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:05:39.761394: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  20/1563 [..............................] - ETA: 8s - loss: 1.4448 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:05:40.059979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2831\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1555\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3e6f9a910>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:06:02.965009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2816 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1547 - sparse_categorical_accuracy: 0.9565\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1233 - sparse_categorical_accuracy: 0.9665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c9ff2100>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb3e5a98662ba18bbfdebe8f315a9e260c1d6da64a84910e2c18caf741bb53f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
