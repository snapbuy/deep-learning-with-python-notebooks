{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:17:27.294566: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-14 10:17:27.294661: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 1.21099055e-01, -2.61743039e-01, -2.35479474e-01,\n",
       "          2.18245983e-01, -1.56665117e-01, -1.61237478e-01,\n",
       "          1.06308162e-01, -2.02214032e-01,  9.13491249e-02,\n",
       "          2.45877743e-01, -1.86160415e-01, -2.29346097e-01,\n",
       "         -8.54595900e-02, -2.14487210e-01,  2.42686510e-01,\n",
       "         -1.55917823e-01,  1.66905969e-01, -2.61988968e-01,\n",
       "          1.26063347e-01,  4.80661094e-02,  2.02316344e-02,\n",
       "          2.23649263e-01,  1.52215034e-01,  1.63554907e-01,\n",
       "         -2.61497974e-01, -2.49633878e-01, -2.07614601e-02,\n",
       "          3.54520977e-02, -5.46512008e-02,  2.40095258e-01,\n",
       "         -1.67693138e-01, -8.57475400e-03, -1.72543481e-01,\n",
       "          1.40400529e-01,  2.01429427e-01,  1.36374325e-01,\n",
       "          3.05347741e-02, -1.61084875e-01, -2.28309125e-01,\n",
       "          3.94340158e-02, -5.32974601e-02,  2.22627819e-01,\n",
       "         -1.34521231e-01, -7.76784420e-02, -2.10926905e-01,\n",
       "          2.69716799e-01, -1.64595097e-01, -2.62337208e-01,\n",
       "         -9.21379328e-02, -9.33448374e-02, -2.55960345e-01,\n",
       "          8.37143660e-02,  1.75442755e-01, -2.92372555e-01,\n",
       "          2.85156906e-01,  1.43372864e-01, -1.25978157e-01,\n",
       "         -2.54718095e-01,  4.68219519e-02, -1.51008978e-01,\n",
       "          2.02003777e-01,  9.57621634e-02,  2.61127532e-01,\n",
       "         -1.91793874e-01],\n",
       "        [-2.87939012e-02, -1.54048875e-01,  5.15188277e-02,\n",
       "         -2.23451436e-01,  9.41990912e-02, -2.28656530e-02,\n",
       "         -2.35823661e-01,  2.24116266e-01,  9.74888504e-02,\n",
       "         -2.18487084e-02, -1.01323411e-01, -1.78110927e-01,\n",
       "         -2.40156949e-01,  7.35962391e-02,  1.95423186e-01,\n",
       "         -2.83768773e-02,  2.70231962e-01, -2.73593068e-02,\n",
       "         -7.95603096e-02,  2.72990346e-01,  2.52834022e-01,\n",
       "          2.01445103e-01, -1.57023638e-01,  7.00974464e-03,\n",
       "         -6.99109882e-02, -9.68745351e-02, -2.11306810e-02,\n",
       "         -2.88703740e-01,  2.87610888e-02,  2.91257858e-01,\n",
       "         -2.52518684e-01, -2.22879380e-01,  1.21965945e-01,\n",
       "         -5.56479245e-02,  6.52885437e-02, -2.02041358e-01,\n",
       "          1.07120246e-01,  1.76422358e-01, -1.85529143e-01,\n",
       "         -5.76966703e-02,  1.16449922e-01,  2.08022118e-01,\n",
       "          2.16265380e-01, -1.76739275e-01,  2.13767529e-01,\n",
       "          2.73054123e-01,  2.95905232e-01, -2.33707994e-01,\n",
       "         -2.02791438e-01, -1.72974348e-01,  2.68062711e-01,\n",
       "          1.88016444e-01, -1.26789808e-01,  2.07722425e-01,\n",
       "          2.78505921e-01, -1.18242234e-01, -1.46584809e-02,\n",
       "          8.03369284e-02, -1.80277258e-01,  2.53891826e-01,\n",
       "          2.33156204e-01, -1.13573834e-01, -1.42022058e-01,\n",
       "         -2.00769529e-01],\n",
       "        [ 1.65342897e-01,  2.24787474e-01, -6.90723062e-02,\n",
       "          2.94748783e-01,  1.87469006e-01,  3.55008543e-02,\n",
       "          2.31924713e-01,  5.16296327e-02, -9.72241163e-04,\n",
       "         -2.20938385e-01, -1.54384926e-01, -1.29640996e-01,\n",
       "         -2.38478065e-01,  1.78907186e-01, -2.95076191e-01,\n",
       "          1.32281482e-01, -1.79380134e-01, -1.97927475e-01,\n",
       "          1.91741139e-01, -2.17800796e-01, -2.18781322e-01,\n",
       "          2.33847499e-02, -1.07901007e-01,  1.79339826e-01,\n",
       "          2.10357130e-01, -1.65758491e-01, -2.49173254e-01,\n",
       "          2.67238498e-01, -2.47367889e-01, -2.18656614e-01,\n",
       "         -2.40585819e-01, -2.04806715e-01, -2.12055832e-01,\n",
       "          1.87954396e-01,  6.28099144e-02,  9.23760831e-02,\n",
       "          2.78465390e-01, -2.47227266e-01, -2.75820166e-01,\n",
       "         -2.61149645e-01, -7.78892785e-02,  2.98331857e-01,\n",
       "          2.95689583e-01,  2.60495365e-01,  5.64742684e-02,\n",
       "          1.72704101e-01,  2.75478423e-01, -1.57952309e-04,\n",
       "         -2.50065595e-01,  9.08126533e-02,  1.53700620e-01,\n",
       "         -4.50833738e-02,  1.66234583e-01, -2.72141576e-01,\n",
       "         -1.00513190e-01, -3.03809345e-02, -7.73276240e-02,\n",
       "         -2.86493748e-01, -2.68490076e-01, -1.97536990e-01,\n",
       "          1.24142677e-01, -4.69779372e-02,  3.91897857e-02,\n",
       "         -1.92771047e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-0.10718292,  0.18584967,  0.10532555, -0.2809266 ,  0.16372699,\n",
       "         -0.06227362, -0.11809582,  0.28028783,  0.260888  ,  0.0320245 ],\n",
       "        [-0.19097269, -0.20817477, -0.20940404,  0.01982403,  0.04037818,\n",
       "          0.00552699, -0.00995281, -0.19601706, -0.07385054, -0.0044952 ],\n",
       "        [ 0.03816527, -0.16645843, -0.18096334,  0.28408524, -0.07431573,\n",
       "         -0.06875025,  0.15508008,  0.10371494, -0.05733198,  0.16177714],\n",
       "        [ 0.10182655,  0.1332384 ,  0.02963901, -0.22239617,  0.0847398 ,\n",
       "          0.27852735,  0.18244645,  0.11657763,  0.26075032, -0.27166367],\n",
       "        [ 0.24829218,  0.08617961, -0.10442492, -0.2841121 ,  0.23988208,\n",
       "         -0.06704059,  0.15516475,  0.2364212 ,  0.04277664,  0.16705674],\n",
       "        [-0.04044762, -0.17586589,  0.13966894, -0.04691495,  0.1807298 ,\n",
       "         -0.17018147,  0.08298433, -0.19087052, -0.02937892,  0.0602462 ],\n",
       "        [ 0.18002585, -0.04956581, -0.13480033, -0.17604457,  0.14988312,\n",
       "          0.1902251 , -0.00314516,  0.1062859 , -0.11375146, -0.13252476],\n",
       "        [ 0.1901496 ,  0.07396916, -0.19850817, -0.01683277,  0.11049625,\n",
       "          0.26230422,  0.24951574,  0.01708069, -0.16426419, -0.06032839],\n",
       "        [-0.19102702, -0.0436822 ,  0.09869021, -0.1222088 , -0.04734217,\n",
       "          0.14081177,  0.2268143 ,  0.25726262, -0.22968365,  0.25249037],\n",
       "        [ 0.10961002,  0.27734104,  0.28048137, -0.16856042, -0.13440712,\n",
       "          0.1674475 ,  0.12514439, -0.01226863, -0.16306894,  0.16180938],\n",
       "        [ 0.24606207,  0.03563768, -0.01377964, -0.11080298,  0.02208763,\n",
       "         -0.24843848,  0.07684648,  0.08176404, -0.08986041,  0.19704497],\n",
       "        [-0.16196546, -0.2235344 , -0.20856853,  0.25979164,  0.08443758,\n",
       "          0.03129679, -0.27126518,  0.13715988, -0.08201651, -0.11438636],\n",
       "        [ 0.10823962, -0.16453296, -0.27970323, -0.04298322, -0.23743312,\n",
       "         -0.0526071 ,  0.04362306, -0.00044155, -0.16616318, -0.24284491],\n",
       "        [ 0.21891645, -0.18744668, -0.04391207,  0.2737367 , -0.03611515,\n",
       "         -0.20855597, -0.21742947,  0.20995855, -0.17864214, -0.09197496],\n",
       "        [ 0.12348118, -0.05911896, -0.28268594,  0.23112115,  0.17034298,\n",
       "          0.16706917,  0.24634174,  0.24821731,  0.2300351 , -0.1787841 ],\n",
       "        [-0.00089234,  0.17858797,  0.19154629, -0.25320852, -0.26848307,\n",
       "          0.09428346, -0.10442364, -0.23333493, -0.11156034, -0.28345296],\n",
       "        [ 0.07587078, -0.1966643 ,  0.10006455,  0.2321628 , -0.09245609,\n",
       "         -0.01962817, -0.11175233, -0.03549777,  0.1420005 ,  0.13418418],\n",
       "        [-0.02716038, -0.00546819, -0.17715177,  0.01154664,  0.21281344,\n",
       "         -0.01753065,  0.07934535,  0.08355156,  0.26337287, -0.05120234],\n",
       "        [ 0.20809764,  0.21999457, -0.12645215,  0.21969756, -0.16060653,\n",
       "         -0.11893833, -0.26223037,  0.1786386 ,  0.17881295,  0.01241887],\n",
       "        [-0.21357806,  0.02781883,  0.15693983,  0.06745112, -0.1427369 ,\n",
       "          0.22404972, -0.12288077,  0.11579335, -0.13541806, -0.03233808],\n",
       "        [-0.01909801, -0.25068092, -0.05639023,  0.10986894, -0.21158531,\n",
       "         -0.15507133, -0.09287767,  0.01874423,  0.05207038, -0.16094923],\n",
       "        [ 0.01834199, -0.25542787, -0.26224428, -0.04631773,  0.16481131,\n",
       "         -0.25977916,  0.26741102, -0.00503328, -0.07368129, -0.09376505],\n",
       "        [-0.26902455,  0.2833664 ,  0.01237375, -0.1690991 ,  0.12429491,\n",
       "          0.19512928,  0.25869843,  0.2284368 ,  0.0731191 , -0.23566006],\n",
       "        [ 0.03872156, -0.12093976, -0.1775177 ,  0.09446296,  0.06778175,\n",
       "         -0.25956014, -0.00212637,  0.08399257, -0.08213925, -0.1023161 ],\n",
       "        [-0.09279913,  0.13616973, -0.19071186, -0.04808895,  0.1630933 ,\n",
       "         -0.02335262, -0.04165089,  0.03590328, -0.26131237,  0.14419693],\n",
       "        [-0.18044303, -0.10929997, -0.11114866, -0.2357042 ,  0.14385912,\n",
       "         -0.04319414,  0.16387239, -0.21862051, -0.08397152,  0.00409386],\n",
       "        [-0.19096449,  0.02339995,  0.04360828, -0.18882006,  0.17128149,\n",
       "         -0.08836836, -0.10970785,  0.26770636, -0.03794782,  0.0104197 ],\n",
       "        [ 0.20248798, -0.15967251,  0.148588  , -0.257623  ,  0.00749645,\n",
       "          0.26959655, -0.09486675, -0.26679516, -0.12030798,  0.04975122],\n",
       "        [ 0.14618757,  0.11732581,  0.03353158, -0.05644317,  0.19234806,\n",
       "          0.15098304,  0.0229463 ,  0.01392731,  0.22582796, -0.04249319],\n",
       "        [ 0.10388499, -0.18508807, -0.04765527,  0.18915817, -0.10611625,\n",
       "         -0.19860417, -0.15029031,  0.03674293, -0.03047046, -0.05110364],\n",
       "        [ 0.06169522,  0.0055432 , -0.10795699, -0.23979275,  0.04432619,\n",
       "         -0.19227937,  0.07458672,  0.12841326,  0.19323233,  0.22713593],\n",
       "        [ 0.08531532, -0.23004714, -0.24738416,  0.05871257,  0.01490971,\n",
       "         -0.11809276, -0.07501288,  0.23493657,  0.24555233,  0.17653072],\n",
       "        [ 0.22152081, -0.06715302, -0.01985097, -0.13276862,  0.0421021 ,\n",
       "          0.24521449,  0.2680733 , -0.13383584, -0.00846061,  0.08511525],\n",
       "        [-0.23876476, -0.2646263 ,  0.0930759 ,  0.0524433 ,  0.22690114,\n",
       "         -0.0273115 , -0.2511452 ,  0.02533594, -0.24923265, -0.28200495],\n",
       "        [-0.25348333, -0.10965124, -0.23821452, -0.25109586,  0.05761772,\n",
       "         -0.04202516, -0.11248337,  0.15339264,  0.03593993, -0.28328866],\n",
       "        [ 0.25077346, -0.11031899, -0.05325809,  0.22586283,  0.24619588,\n",
       "         -0.27701008,  0.14026907, -0.09751396,  0.22774407,  0.17598638],\n",
       "        [ 0.14781046, -0.16825423,  0.1754711 ,  0.03675887, -0.16913863,\n",
       "          0.14260119, -0.23593773, -0.00663757, -0.09290048,  0.22548208],\n",
       "        [ 0.10633445,  0.1991559 , -0.22492613, -0.28454128,  0.08775952,\n",
       "          0.09811404,  0.0511665 , -0.00234476,  0.11707661, -0.17344448],\n",
       "        [-0.14377166, -0.10737586, -0.03296584, -0.17848933, -0.00527313,\n",
       "          0.28278032, -0.18537524, -0.17796957, -0.12770836,  0.06674072],\n",
       "        [ 0.27490607, -0.04121417,  0.19721523,  0.02749866,  0.26081797,\n",
       "          0.09159097, -0.16092724,  0.22992077, -0.06107566, -0.19716093],\n",
       "        [ 0.09464809,  0.14061156,  0.21466109,  0.19803703, -0.15541634,\n",
       "         -0.00423208,  0.15277654,  0.17140672,  0.15859741,  0.12809643],\n",
       "        [ 0.22639892,  0.16877514,  0.06903166, -0.27318195,  0.07521334,\n",
       "          0.03433686,  0.0776372 , -0.06497772, -0.0294202 , -0.1389671 ],\n",
       "        [ 0.14097247,  0.02364373,  0.04269814,  0.06919158,  0.19011492,\n",
       "          0.24380949,  0.21669582,  0.237286  , -0.17243077,  0.09334162],\n",
       "        [-0.17812143, -0.09638618, -0.24992688,  0.11353326,  0.11493993,\n",
       "          0.2591705 , -0.17450368,  0.07139981, -0.22957414, -0.17601165],\n",
       "        [ 0.28201208,  0.06100926, -0.18613362,  0.27286252,  0.08421096,\n",
       "          0.21093473, -0.17309825, -0.08876726, -0.18885341,  0.16451985],\n",
       "        [-0.15625314,  0.2582114 ,  0.07282826,  0.07816395,  0.19660613,\n",
       "         -0.03797422, -0.14077389, -0.00569645,  0.27219412, -0.11667097],\n",
       "        [ 0.26041308,  0.0276508 , -0.1289711 ,  0.20057642, -0.01751313,\n",
       "          0.04649106,  0.03575709,  0.1418781 ,  0.08194673,  0.11039191],\n",
       "        [-0.25964174,  0.13279006,  0.0639475 ,  0.2380183 , -0.04455253,\n",
       "          0.09945497, -0.22108638,  0.1765388 , -0.06691262,  0.11705941],\n",
       "        [-0.24502197,  0.20575383,  0.25835332, -0.23758186, -0.24830067,\n",
       "          0.15256852,  0.20231757, -0.12412845,  0.04335627, -0.20331588],\n",
       "        [-0.21868502, -0.0039297 ,  0.08910921, -0.11228661, -0.17925566,\n",
       "          0.04819208, -0.07693394, -0.09732285,  0.26066628, -0.0059016 ],\n",
       "        [ 0.24875799,  0.16016972,  0.14713353,  0.06490535,  0.02718773,\n",
       "          0.1017949 , -0.23290268,  0.05854225, -0.15068291,  0.16876462],\n",
       "        [-0.19027555,  0.15106669,  0.23029974, -0.2323815 , -0.1397753 ,\n",
       "         -0.16126165,  0.04045931,  0.03239095,  0.25892028, -0.2629599 ],\n",
       "        [ 0.09682897,  0.25184038, -0.1083221 , -0.17281346,  0.152165  ,\n",
       "          0.13112164,  0.27892646, -0.09973203, -0.213575  , -0.21834897],\n",
       "        [-0.12367406,  0.02997527,  0.05063975, -0.20652813,  0.09009627,\n",
       "         -0.23232101,  0.01679093,  0.26873943, -0.26479173, -0.255413  ],\n",
       "        [ 0.16617492,  0.25615087,  0.2177504 ,  0.22845516,  0.25833187,\n",
       "          0.19632664, -0.28145143, -0.19846968,  0.14913008, -0.1407762 ],\n",
       "        [ 0.13630068, -0.14125311,  0.23548988, -0.0522369 ,  0.15274504,\n",
       "         -0.25113782,  0.15748778, -0.2032833 , -0.20691977,  0.2359111 ],\n",
       "        [ 0.00755516, -0.23419495,  0.23553964,  0.05152449, -0.08409107,\n",
       "         -0.05318619,  0.10147521,  0.1802243 , -0.2504201 , -0.12738909],\n",
       "        [-0.06155501,  0.02982599, -0.21932182, -0.03626831,  0.03827369,\n",
       "         -0.21065733, -0.16365108, -0.10952468, -0.27878124,  0.14979616],\n",
       "        [-0.19462478,  0.21948221, -0.18294923, -0.18325168,  0.24988982,\n",
       "          0.09482399,  0.27752718,  0.17133477,  0.227132  ,  0.07330015],\n",
       "        [-0.03385505,  0.07938826,  0.13241452,  0.09258813,  0.07652068,\n",
       "         -0.19999856, -0.00514817,  0.00249138,  0.06321579,  0.16763285],\n",
       "        [-0.16758499,  0.025222  , -0.22511655, -0.03482784, -0.17533126,\n",
       "         -0.05170567,  0.07699394,  0.25699338, -0.00428101, -0.23291579],\n",
       "        [-0.2763187 ,  0.107979  , -0.10558312, -0.12506199, -0.14888738,\n",
       "         -0.26790208, -0.00456607,  0.09440362,  0.21990022, -0.17744105],\n",
       "        [-0.2708875 ,  0.07736841, -0.18729162,  0.24587658, -0.10410571,\n",
       "          0.09396362, -0.21640706,  0.22258398, -0.16910604, -0.23728058],\n",
       "        [-0.15274464,  0.04595214, -0.04808101, -0.02680925,  0.2757289 ,\n",
       "         -0.21272483, -0.0709434 , -0.0206427 ,  0.17579576, -0.18617335]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:17:54.177667: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-14 10:17:54.527349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 12ms/step - loss: 27.4476 - priority_loss: 0.3262 - department_loss: 27.1214 - priority_mean_absolute_error: 0.4938 - department_accuracy: 0.2898\n",
      "14/40 [=========>....................] - ETA: 0s - loss: 28.4525 - priority_loss: 0.3488 - department_loss: 28.1036 - priority_mean_absolute_error: 0.5161 - department_accuracy: 0.0692"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:17:57.353604: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 8ms/step - loss: 27.6370 - priority_loss: 0.3394 - department_loss: 27.2976 - priority_mean_absolute_error: 0.5067 - department_accuracy: 0.0734\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:17:57.869686: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/40 [..............................] - ETA: 15s - loss: 28.3975 - priority_loss: 0.4553 - department_loss: 27.9422 - priority_mean_absolute_error: 0.5863 - department_accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:01.393408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 13ms/step - loss: 33.1376 - priority_loss: 0.3342 - department_loss: 32.8034 - priority_mean_absolute_error: 0.5018 - department_accuracy: 0.2789\n",
      "13/40 [========>.....................] - ETA: 0s - loss: 33.8594 - priority_loss: 0.3226 - department_loss: 33.5367 - priority_mean_absolute_error: 0.4899 - department_accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:02.187048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 8ms/step - loss: 32.0612 - priority_loss: 0.3260 - department_loss: 31.7351 - priority_mean_absolute_error: 0.4933 - department_accuracy: 0.0695\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:02.713413: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x17f396520>,\n",
       " <keras.engine.input_layer.InputLayer at 0x17f8f6940>,\n",
       " <keras.engine.input_layer.InputLayer at 0x17f8f6e20>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x17f8f6a60>,\n",
       " <keras.layers.core.dense.Dense at 0x17f8f6730>,\n",
       " <keras.layers.core.dense.Dense at 0x17f8f0670>,\n",
       " <keras.layers.core.dense.Dense at 0x17f90b490>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/40 [==>...........................] - ETA: 0s - loss: 43.4971 - output_1_loss: 0.2390 - output_2_loss: 43.2580 - output_1_mean_absolute_error: 0.4013 - output_2_accuracy: 0.2313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:17.169249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 13ms/step - loss: 20.7101 - output_1_loss: 0.3180 - output_2_loss: 20.3921 - output_1_mean_absolute_error: 0.4844 - output_2_accuracy: 0.2164\n",
      "14/40 [=========>....................] - ETA: 0s - loss: 25.9272 - output_1_loss: 0.3166 - output_2_loss: 25.6106 - output_1_mean_absolute_error: 0.4839 - output_2_accuracy: 0.0603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:18.152507: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 8ms/step - loss: 24.0874 - output_1_loss: 0.3260 - output_2_loss: 23.7613 - output_1_mean_absolute_error: 0.4933 - output_2_accuracy: 0.0688\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:18.602356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:30.687174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.9168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:18:41.157591: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2821 - accuracy: 0.9168 - val_loss: 0.1530 - val_accuracy: 0.9561\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1502 - accuracy: 0.9576 - val_loss: 0.1204 - val_accuracy: 0.9672\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1268 - accuracy: 0.9665 - val_loss: 0.1192 - val_accuracy: 0.9683\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1059 - accuracy: 0.9718\n",
      " 93/313 [=======>......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:19:05.471205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:24:01.295845: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.9147 - rmse: 7.1946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:24:12.285274: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.2863 - accuracy: 0.9147 - rmse: 7.1946 - val_loss: 0.1462 - val_accuracy: 0.9592 - val_rmse: 7.3571\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1533 - accuracy: 0.9573 - rmse: 7.3651 - val_loss: 0.1326 - val_accuracy: 0.9635 - val_rmse: 7.4023\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1275 - accuracy: 0.9661 - rmse: 7.3975 - val_loss: 0.1109 - val_accuracy: 0.9710 - val_rmse: 7.4209\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9717 - rmse: 7.4335\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  17/1563 [..............................] - ETA: 10s - loss: 1.4357 - accuracy: 0.5717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:24:46.604317: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.9151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:24:56.530568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2827 - accuracy: 0.9152 - val_loss: 0.1499 - val_accuracy: 0.9594\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1547 - accuracy: 0.9571 - val_loss: 0.1236 - val_accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1283 - accuracy: 0.9657 - val_loss: 0.1233 - val_accuracy: 0.9669\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1105 - accuracy: 0.9705 - val_loss: 0.1313 - val_accuracy: 0.9696\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1042 - accuracy: 0.9742 - val_loss: 0.1130 - val_accuracy: 0.9745\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0964 - accuracy: 0.9765 - val_loss: 0.1200 - val_accuracy: 0.9749\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0885 - accuracy: 0.9790 - val_loss: 0.1334 - val_accuracy: 0.9745\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0869 - accuracy: 0.9793 - val_loss: 0.1186 - val_accuracy: 0.9769\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0827 - accuracy: 0.9804 - val_loss: 0.1282 - val_accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0779 - accuracy: 0.9821 - val_loss: 0.1288 - val_accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x297e57dc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   8/1563 [..............................] - ETA: 11s - loss: 1.9722 - accuracy: 0.3438 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:26:43.309695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.9148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:26:53.442962: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2851 - accuracy: 0.9148 - val_loss: 0.1529 - val_accuracy: 0.9561\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1536 - accuracy: 0.9561 - val_loss: 0.1217 - val_accuracy: 0.9665\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1249 - accuracy: 0.9657 - val_loss: 0.1172 - val_accuracy: 0.9695\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1122 - accuracy: 0.9707 - val_loss: 0.1149 - val_accuracy: 0.9722\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0992 - accuracy: 0.9743 - val_loss: 0.1168 - val_accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0928 - accuracy: 0.9773 - val_loss: 0.1212 - val_accuracy: 0.9737\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0882 - accuracy: 0.9787 - val_loss: 0.1123 - val_accuracy: 0.9789\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0870 - accuracy: 0.9795 - val_loss: 0.1204 - val_accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0802 - accuracy: 0.9808 - val_loss: 0.1127 - val_accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0752 - accuracy: 0.9831 - val_loss: 0.1290 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d310b040>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1563 [..............................] - ETA: 7:53 - loss: 2.4711 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:29:46.180931: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.9162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:29:57.959748: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.2833 - accuracy: 0.9162 - val_loss: 0.1521 - val_accuracy: 0.9550\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1535 - accuracy: 0.9556 - val_loss: 0.1201 - val_accuracy: 0.9673\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1268 - accuracy: 0.9661 - val_loss: 0.1159 - val_accuracy: 0.9707\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1139 - accuracy: 0.9705 - val_loss: 0.1129 - val_accuracy: 0.9721\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1001 - accuracy: 0.9750 - val_loss: 0.1102 - val_accuracy: 0.9746\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0957 - accuracy: 0.9768 - val_loss: 0.1202 - val_accuracy: 0.9726\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0884 - accuracy: 0.9784 - val_loss: 0.1197 - val_accuracy: 0.9740\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0853 - accuracy: 0.9797 - val_loss: 0.1191 - val_accuracy: 0.9766\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0779 - accuracy: 0.9814 - val_loss: 0.1184 - val_accuracy: 0.9774\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0788 - accuracy: 0.9819 - val_loss: 0.1234 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c4d73640>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/opt/homebrew/bin/tensorboard\", line 5, in <module>\n",
       "    from tensorboard.main import run_main\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/main.py\", line 27, in <module>\n",
       "    from tensorboard import default\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/default.py\", line 33, in <module>\n",
       "    from tensorboard.plugins.audio import audio_plugin\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/plugins/audio/audio_plugin.py\", line 25, in <module>\n",
       "    from tensorboard.data import provider\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/data/__init__.py\", line 17, in <module>\n",
       "    from tensorboard.data import experimental  # noqa: F401\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/data/experimental/__init__.py\", line 17, in <module>\n",
       "    from tensorboard.data.experimental.experiment_from_dev import (  # noqa: F401\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/tensorboard/data/experimental/experiment_from_dev.py\", line 21, in <module>\n",
       "    import grpc\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/grpc/__init__.py\", line 22, in <module>\n",
       "    from grpc import _compression\n",
       "  File \"/opt/homebrew/lib/python3.9/site-packages/grpc/_compression.py\", line 15, in <module>\n",
       "    from grpc._cython import cygrpc\n",
       "ImportError: dlopen(/opt/homebrew/lib/python3.9/site-packages/grpc/_cython/cygrpc.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/lib/python3.9/site-packages/grpc/_cython/cygrpc.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have (x86_64), need (arm64e)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9190\n",
      "...loss: 0.2750\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9656\n",
      "...loss: 0.1232\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9787\n",
      "...loss: 0.0799\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9603\n",
      "...val_loss: 0.1733\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:34:08.553839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9603\n",
      "...val_loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:34:09.276576: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  17/1563 [..............................] - ETA: 9s - loss: 1.4470 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:34:14.319629: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2851\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1545\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x175ae7a00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:34:42.709834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2819 - sparse_categorical_accuracy: 0.9169\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1298 - sparse_categorical_accuracy: 0.9650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x175d35e50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb3e5a98662ba18bbfdebe8f315a9e260c1d6da64a84910e2c18caf741bb53f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
